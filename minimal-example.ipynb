{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.train.ensemble_trainer import make_trainer\n",
    "from src.models import HNN, CHNN\n",
    "from src.systems.chain_pendulum import ChainPendulum\n",
    "from src.datasets import get_chaotic_eval_dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def trace_plot(t, y, ax, y_std=None, min_y=-np.inf, max_y=np.inf,\n",
    "               kind='region', color='black',\n",
    "               plt_args=None):\n",
    "    '''\n",
    "    Arguments:\n",
    "        zt: Assumes zeroth dimension is number of samples.\n",
    "        ax: Matplotlib Axis\n",
    "        pos: Positive quantity flag (for range bounds)\n",
    "    '''\n",
    "    assert kind in ['region', 'bound']\n",
    "    plt_args = plt_args or dict()\n",
    "\n",
    "    mu = np.mean(y, axis=0)\n",
    "    std = np.std(y, axis=0) if y_std is None else y_std\n",
    "\n",
    "    ax.plot(t, mu, c=color, **plt_args)\n",
    "\n",
    "    if y.shape[0] == 1:\n",
    "        return\n",
    "\n",
    "    lower = np.clip(mu - 2. * std, min_y, max_y)\n",
    "    upper = np.clip(mu + 2. * std, min_y, max_y)\n",
    "\n",
    "    if kind == 'region':\n",
    "        ax.fill_between(ts, lower, upper, color=color, alpha=0.2)\n",
    "    elif kind == 'bound':\n",
    "        ax.plot(np.array([t, t]).T, np.array([lower, upper]).T, c=color, dashes=[8,4])\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble member 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e9c8c878754f5b8f3fe99f9d996365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Minibatch_Loss  Train_MAE    lr0  nfe  test_MAE\n",
      "0        0.128798   0.122779  0.003  0.0  0.127001\n",
      "    Minibatch_Loss  Train_MAE       lr0  nfe  test_MAE\n",
      "14        0.053317   0.054422  0.002951  0.8  0.055059\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "26        0.028735   0.027445  0.002823  0.421053  0.025779\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "38        0.022321   0.020103  0.002621  0.285714  0.018597\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "50        0.008935   0.010073  0.002358  0.216216  0.009306\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "62        0.004661   0.005948  0.002047  0.173913  0.006027\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "73        0.006398   0.006731  0.001735  0.146789  0.006517\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "84        0.003144   0.004247  0.001412  0.126984  0.004225\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "95        0.003318   0.003034  0.001093  0.111888  0.003014\n",
      "     Minibatch_Loss  Train_MAE       lr0  nfe  test_MAE\n",
      "106        0.002748   0.002272  0.000793  0.1   0.00241\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "117        0.001425   0.002034  0.000526  0.090395  0.002196\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "127        0.001345   0.001491  0.000322  0.082902  0.001633\n",
      "     Minibatch_Loss  Train_MAE      lr0      nfe  test_MAE\n",
      "138        0.001727   0.001301  0.00015  0.07619  0.001455\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "149        0.001085   0.001227  0.000041  0.070485  0.001359\n",
      "\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "159             NaN   0.001206  0.000003  0.065574  0.001344\n",
      "Training ensemble member 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c3526eab0443c7a4d18c7e61701dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Minibatch_Loss  Train_MAE    lr0  nfe  test_MAE\n",
      "0        0.120503   0.120837  0.003  0.0   0.12431\n",
      "    Minibatch_Loss  Train_MAE       lr0  nfe  test_MAE\n",
      "10        0.045549   0.052132  0.002977  1.0  0.049603\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "21        0.038472   0.038553  0.002886  0.484848  0.036564\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "31        0.024269   0.026172  0.002747  0.326531  0.024004\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "39        0.020267   0.020428  0.002601  0.253968  0.018522\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "48        0.010117   0.013487  0.002405  0.205128  0.012842\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "58        0.007359   0.006967  0.002155  0.170213  0.006287\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "68        0.007406   0.006881  0.001879  0.145455  0.006997\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "78        0.007072   0.006462  0.001588  0.126984  0.006479\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "90        0.005256   0.005132  0.001236  0.111111  0.005417\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "101        0.003972   0.003803  0.000926  0.099379  0.004218\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "112         0.00313   0.002539  0.000642  0.089888  0.002749\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "124        0.001061   0.001501  0.000379  0.081633  0.001702\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "136        0.001227   0.001325  0.000177  0.074766  0.001546\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "148         0.00133   0.001242  0.000049  0.068966  0.001441\n",
      "\n",
      "     Minibatch_Loss  Train_MAE       lr0    nfe  test_MAE\n",
      "159             NaN   0.001232  0.000003  0.064   0.00143\n",
      "Training ensemble member 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d3b0619b5c4e61b0bfd1daa1a7083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Minibatch_Loss  Train_MAE    lr0  nfe  test_MAE\n",
      "0        0.117283   0.119897  0.003  0.0  0.122648\n",
      "   Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "9        0.050904   0.050611  0.002982  1.066667  0.048483\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "19        0.046912   0.049103  0.002907  0.516129  0.047653\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "29        0.033687   0.037001  0.002779  0.340426  0.037483\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "38        0.027635   0.027543  0.002621  0.258065  0.027289\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "48        0.020556   0.021232  0.002405  0.205128  0.020333\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "59        0.016804   0.016388  0.002128  0.168421  0.015951\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "68        0.012911   0.013568  0.001879  0.145455  0.012976\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "78        0.010082    0.00969  0.001588  0.126984  0.009553\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "88        0.008737   0.008704  0.001294  0.112676  0.008725\n",
      "     Minibatch_Loss  Train_MAE       lr0  nfe  test_MAE\n",
      "100        0.004661   0.005215  0.000953  0.1  0.005099\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "112        0.004418   0.004321  0.000642  0.089888  0.004352\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "122        0.003297   0.002673  0.000419  0.082474  0.002642\n",
      "     Minibatch_Loss  Train_MAE       lr0      nfe  test_MAE\n",
      "132        0.001974   0.002451  0.000237  0.07619  0.002468\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "144         0.00274    0.00233  0.000083  0.070175  0.002327\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "156        0.002174   0.002259  0.000007  0.065041  0.002261\n",
      "\n",
      "     Minibatch_Loss  Train_MAE       lr0     nfe  test_MAE\n",
      "159             NaN   0.002258  0.000003  0.0625   0.00226\n",
      "Training ensemble member 3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba6ea4f75544fa7b351bf43999dba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Minibatch_Loss  Train_MAE    lr0  nfe  test_MAE\n",
      "0        0.125439   0.127919  0.003  0.0  0.132452\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "11        0.068868   0.066223  0.002971  0.941176  0.065647\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "22        0.033319   0.036758  0.002874  0.470588  0.034467\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "33        0.022233   0.025205  0.002714  0.313725  0.023914\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "44         0.01343   0.016361  0.002496  0.235294  0.015352\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "55        0.012123   0.012364  0.002233  0.188235  0.012083\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "66        0.008661   0.009432  0.001935  0.156863  0.009328\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "77        0.005583   0.005234  0.001618  0.134454  0.005025\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "88        0.004279    0.00416  0.001294  0.117647   0.00401\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "99        0.003385   0.003308  0.000981  0.104575  0.003626\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "110        0.002414   0.002685  0.000691  0.094118  0.002891\n",
      "     Minibatch_Loss  Train_MAE      lr0       nfe  test_MAE\n",
      "120        0.001837   0.001592  0.00046  0.086022  0.001828\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "131        0.001357    0.00132  0.000253  0.078818  0.001561\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "141         0.00183   0.001225  0.000114  0.073059  0.001475\n",
      "     Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "152        0.000956     0.0011  0.000023  0.067797  0.001346\n",
      "\n",
      "     Minibatch_Loss  Train_MAE       lr0    nfe  test_MAE\n",
      "159             NaN   0.001099  0.000003  0.064   0.00135\n",
      "Training ensemble member 4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d909c1ce93334fffa0df796c52fd244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train', max=40.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Minibatch_Loss  Train_MAE    lr0  nfe  test_MAE\n",
      "0        0.120367   0.121233  0.003  0.0  0.124926\n",
      "    Minibatch_Loss  Train_MAE       lr0       nfe  test_MAE\n",
      "11        0.057447   0.056907  0.002971  0.941176  0.056552\n"
     ]
    }
   ],
   "source": [
    "os.environ['DATADIR'] = '.'\n",
    "\n",
    "cfg = {\n",
    "    \"num_bodies\": 2,\n",
    "    \"lr\": 3e-3,\n",
    "    \"tau\": 10.0,\n",
    "    \"C\": 5,\n",
    "    \"num_epochs\": 40,\n",
    "    \"uq_type\": \"deep-ensemble\",\n",
    "    \"device\": 'cuda:0' if torch.cuda.is_available() else None\n",
    "}\n",
    "\n",
    "body = ChainPendulum(cfg['num_bodies'])\n",
    "network = CHNN\n",
    "trainer = make_trainer(**cfg, network=network, body=body)\n",
    "trainer.train(cfg['num_epochs'])\n",
    "\n",
    "n_init = 10\n",
    "n_samples = 5\n",
    "evald = get_chaotic_eval_dataset(body, n_init=n_init, n_samples=n_samples)\n",
    "\n",
    "model = trainer.model.to(cfg['device'])\n",
    "ts = evald['ts'].to(cfg['device'])\n",
    "z0_orig = evald['z0_orig'].to(cfg['device'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_zt = trainer.model(z0_orig, ts).cpu()\n",
    "\n",
    "ts = ts.cpu().numpy()\n",
    "pred_zt = pred_zt.numpy()\n",
    "true_zt = evald['true_zt'].numpy()\n",
    "true_zt_chaos = evald['true_zt_chaos'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T, n_dof = ts.shape[-1], true_zt_chaos.shape[-1]\n",
    "for init_id in range(n_init):\n",
    "    \n",
    "    fig, ax = plt.subplots(n_dof, cfg['num_bodies'], figsize=(10, 10))\n",
    "    for b_id in range(cfg['num_bodies']):\n",
    "        \n",
    "        dof_label = ['x', 'y']\n",
    "        for dof_id in range(n_dof):\n",
    "            ax[dof_id, b_id].set_title(f'Body {b_id + 1} $\\mid$ Dimension {dof_label[dof_id]}')\n",
    "            ax[dof_id, b_id].set_xlabel('t')\n",
    "\n",
    "            trace_plot(ts, true_zt[np.newaxis, init_id, :, 0, b_id, dof_id], ax[dof_id, b_id],\n",
    "                       color=(.2,.2,.2), plt_args=dict(dashes=[4,2]))\n",
    "\n",
    "            trace_plot(ts, true_zt_chaos[:, init_id, :, 0, b_id, dof_id], ax[dof_id, b_id],\n",
    "                       color=(.6,.6,.6))\n",
    "\n",
    "            trace_plot(ts, pred_zt[:, init_id, :, 0, b_id, dof_id], ax[dof_id, b_id], kind='bound', \n",
    "                       color=(.2,.2,1.,.75))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'Init {init_id + 1}', fontsize=16, y=1.01)\n",
    "    plt.show(fig)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
