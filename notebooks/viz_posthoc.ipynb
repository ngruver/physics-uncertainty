{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "For a given set training noise, compare the relative error over time. This requires evaluation trajectory dumps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "\n",
    "# sweep_id = 'snym/physics-uncertainty-exps/hye2w7je'\n",
    "sweep_id = None\n",
    "\n",
    "assert sweep_id is not None, \"Add the sweep ID\"\n",
    "\n",
    "dump_dir = os.path.abspath('../.log')\n",
    "\n",
    "def download_runs():\n",
    "    api = wandb.Api()\n",
    "    sweep = api.sweep(sweep_id)\n",
    "    for run in sweep.runs:\n",
    "        download_root = os.path.join(dump_dir, sweep.name, run.name)\n",
    "        for f in run.files():\n",
    "            if f.name == 'data.pt':\n",
    "                fpath = os.path.join(download_root, f.name)\n",
    "                if not os.path.isfile(fpath):\n",
    "                    f.download(root=download_root)\n",
    "                yield run.name, run.config, parse_dump(torch.load(fpath))\n",
    "\n",
    "def parse_dump(dump):\n",
    "    ts = dump.get('ts')\n",
    "    # z0_orig = dump.get('z0_orig')\n",
    "    true_zt = dump.get('true_zt')\n",
    "    true_zt_chaos = dump.get('true_zt_chaos').permute(1, 0, 2, 3, 4, 5)\n",
    "    pred_zt = dump.get('pred_zt')\n",
    "\n",
    "    return ts, true_zt, true_zt_chaos, pred_zt"
   ]
  },
  {
   "source": [
    "## Metric computations\n",
    "\n",
    "Everything that needs to be computed for final graphs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rel_error(ref, pred):\n",
    "    '''\n",
    "    N is the number of initial conditions.\n",
    "    M is the number of samples in prediction\n",
    "    The first dimension \"2\" corresponds to position + velocity.\n",
    "    B is the number of bodies.\n",
    "    The last dimension \"2\" corresponds to xy.\n",
    "\n",
    "    Arguments:\n",
    "        ref: N x T x 2 x B x 2\n",
    "        pred: M x N x T x 2 x B x 2\n",
    "    '''\n",
    "    delta_z = ref.unsqueeze(0) - pred  # M x N x T x 2 x B x 2\n",
    "    all_err = delta_z.pow(2).sum(dim=-1).sum(dim=-1).sum(dim=-1).sqrt()  # M x N x T\n",
    "\n",
    "    sum_z = ref.unsqueeze(0) + pred  # M x N x T x 2 x B x 2\n",
    "    pred_rel_err = all_err / sum_z.pow(2).sum(dim=-1).sum(dim=-1).sum(dim=-1).sqrt()  # M x N x T\n",
    "\n",
    "    return pred_rel_err\n",
    "\n",
    "def compute_geom_mean(ts, values):\n",
    "    '''Geometric mean of a continuous function over time.\n",
    "    Arguments:\n",
    "        ts: T\n",
    "        values: ... x T\n",
    "    '''\n",
    "    t_range = ts.max() - ts.min()\n",
    "    return torch.trapz((values + 1e-8).log(), ts).div(t_range).exp()  # ...\n",
    "\n",
    "\n",
    "def compute_likelihood(ref, pred):\n",
    "  '''\n",
    "  Likelihood of the reference under Gaussian estimated\n",
    "  by the samples, factored over time.\n",
    "  Arguments:\n",
    "    ref: N x T x 2 x B x 2\n",
    "    pred: M x N x T x 2 x B x 2\n",
    "  '''\n",
    "  batch_shape = pred.shape[:3]\n",
    "\n",
    "  pred_mu = pred.view(*batch_shape, -1).mean(dim=0)\n",
    "  pred_std = pred.view(*batch_shape, -1).std(dim=0) + 1e-6\n",
    "  pred_std[torch.isnan(pred_std)] = 1e-6\n",
    "  pred_dist = torch.distributions.MultivariateNormal(pred_mu, pred_std.diag_embed())\n",
    "\n",
    "  log_prob = pred_dist.log_prob(ref.view(*ref.shape[:2], -1))  ## N x T\n",
    "  return log_prob\n",
    "\n",
    "def compute_metrics(ts, true_zt, true_zt_chaos, pred_zt):\n",
    "    assert ts.shape == true_zt.shape[1:2]\n",
    "    assert true_zt_chaos.shape[1:] == true_zt.shape\n",
    "    assert true_zt_chaos.shape == pred_zt.shape\n",
    "\n",
    "    ## Uncollapsed relative error, \n",
    "    rel_err = compute_rel_error(true_zt, pred_zt)  # M x N x T\n",
    "\n",
    "    ## Relative error for the prediction (after BMA), for time-evolution plots.\n",
    "    pred_rel_err =  compute_rel_error(true_zt, pred_zt.mean(dim=0, keepdim=True)).squeeze(0)  # N x T\n",
    "\n",
    "    ## Relative error for deterministic prediction, using zeroth model. (Is this fine?)\n",
    "    determ_rel_err =  compute_rel_error(true_zt, pred_zt[:1]).squeeze(0)  # N x T\n",
    "\n",
    "    ## For bar plots of error comparison.\n",
    "    geom_pred_err = compute_geom_mean(ts, pred_rel_err)\n",
    "\n",
    "    ## For likelihood evolution over time, over all eval trajectories\n",
    "    chaos_likelihood = compute_likelihood(true_zt, true_zt_chaos)  # N x T\n",
    "    pred_likelihood = compute_likelihood(true_zt, pred_zt)  # N x T\n",
    "\n",
    "    return dict(\n",
    "        rel_err=rel_err,\n",
    "        pred_rel_err=pred_rel_err,\n",
    "        determ_rel_err=determ_rel_err,\n",
    "        geom_pred_err=geom_pred_err,\n",
    "        chaos_likelihood=chaos_likelihood,\n",
    "        pred_likelihood=pred_likelihood\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, cfg, dump in download_runs():\n",
    "    compute_metrics(*dump)\n",
    "\n",
    "## TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}